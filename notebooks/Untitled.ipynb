{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1050184-f63d-4eca-99f9-c34f02e770a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdwatcher.config import DATA_PREP_CONFIG, PATHS, TRAINING_CONFIG\n",
    "from birdwatcher.ml.evaluation import get_model_performance_metrics\n",
    "from birdwatcher.ml.inference import get_trained_inference_pipeline\n",
    "from birdwatcher.ml.training import _get_train_test_data, train_save_inference_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27cc0939-212e-4d45-a94c-211500034fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 00:51:04,850:INFO:inference: Getting dataprep and feature generation pipelines.\n",
      "2023-06-11 00:51:04,852:INFO:inference: Loading trained pca from /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/trained_pca.pkl.\n",
      "2023-06-11 00:51:05,204:INFO:inference: Loading trained model from /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/trained_model.pkl.\n",
      "2023-06-11 00:51:05,205:INFO:inference: Combining dataprep, feature generation, pca and model into an inference pipeline.\n"
     ]
    }
   ],
   "source": [
    "from birdwatcher.ml.inference import (\n",
    "    _generate_inference_dataprep_kwargs,\n",
    "    _generate_inference_tfidf_kwargs, \n",
    "    get_trained_inference_pipeline\n",
    ")\n",
    "\n",
    "\n",
    "inference_pipeline = get_trained_inference_pipeline(data_key=\"covid\", save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "431787d6-8e49-4e8b-ae78-ae7a32c58d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataprep': Pipeline(steps=[('dataprep',\n",
       "                  FunctionTransformer(func=<function process_text_df at 0x7f932491af70>,\n",
       "                                      kw_args={'data_key': 'covid',\n",
       "                                               'text_col': 'text'}))]),\n",
       " 'feature_generation': Pipeline(steps=[('tfidf',\n",
       "                  FunctionTransformer(func=<function generate_tfidf_df at 0x7f9324924430>,\n",
       "                                      kw_args={'data_key': 'covid',\n",
       "                                               'save': False,\n",
       "                                               'text_col_proc': 'text_processed'}))]),\n",
       " 'pca': PCAPlotIt(),\n",
       " 'classifier': LogisticRegression(l1_ratio=0.05, n_jobs=-1, penalty='elasticnet',\n",
       "                    random_state=123, solver='saga')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_pipeline.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c335e35-4302-45e0-9622-6ef9147d49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "from birdwatcher.dataprep.prep import _generate_raw_proc_path\n",
    "\n",
    "\n",
    "raw_path = _generate_raw_proc_path(\n",
    "    config_dict=DATA_PREP_CONFIG.processing_info[\"covid\"],\n",
    "    df_type=\"raw\"\n",
    ")\n",
    "covid_raw = pd.read_parquet(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c425106e-6221-415d-b02d-15c52aeec7d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "2023-06-11 00:51:15,121:INFO:prep: Raw text has been processed for data_key: 'covid'.\n",
      "2023-06-11 00:51:15,122:INFO:feature_generation:Found vectorizer. Loading from /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/tfidf_vectorizer.pkl.\n",
      "2023-06-11 00:51:15,125:INFO:feature_generation:Transforming df_proc using fitted Tfidfvectorizer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_preds = inference_pipeline.predict(covid_raw)\n",
    "covid_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e60e51-6fe7-4665-b24f-5ed4bb2da189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "from birdwatcher.ml.inference import (\n",
    "    _generate_inference_dataprep_kwargs,\n",
    "    _generate_inference_tfidf_kwargs\n",
    ")\n",
    "from birdwatcher.dataprep.prep import get_dataprep_pipeline\n",
    "from birdwatcher.ml.feature_generation import get_feature_generation_pipeline\n",
    "\n",
    "\n",
    "with open(PATHS.dc_run_date_info, \"rb\") as infile:\n",
    "    run_info = pickle.load(infile)\n",
    "end_date_name = run_info.end_date_name\n",
    "data_key = \"covid\"\n",
    "save = False\n",
    "\n",
    "INFERENCE_DATAPREP_KWARGS = _generate_inference_dataprep_kwargs(\n",
    "    data_key=data_key,\n",
    "    end_date_name=end_date_name,\n",
    "    save=save\n",
    ")\n",
    "INFERENCE_TFIDF_KWARGS = _generate_inference_tfidf_kwargs(\n",
    "    data_key=data_key,\n",
    "    save=save\n",
    ")\n",
    "dataprep_pipeline = get_dataprep_pipeline(\n",
    "    dataprep_kwargs=INFERENCE_DATAPREP_KWARGS\n",
    ")\n",
    "feature_generation_pipeline = get_feature_generation_pipeline(\n",
    "    tfidf_kwargs=INFERENCE_TFIDF_KWARGS\n",
    ")\n",
    "\n",
    "\n",
    "test_pipe = Pipeline(steps=[\n",
    "    (\"dataprep\", dataprep_pipeline),\n",
    "    (\"feature_generation\", feature_generation_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7bb0201-4041-4d94-95d4-6e501bbf255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    3.9s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    4.0s finished\n",
      "2023-06-11 00:33:25,252:INFO:prep: Raw text has been processed for data_key: 'covid'.\n",
      "2023-06-11 00:33:25,254:INFO:feature_generation:Found vectorizer. Loading from /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/tfidf_vectorizer.pkl.\n",
      "2023-06-11 00:33:25,258:INFO:feature_generation:Transforming df_proc using fitted Tfidfvectorizer.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>026</th>\n",
       "      <th>04</th>\n",
       "      <th>0430</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>0809</th>\n",
       "      <th>0815</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zune</th>\n",
       "      <th>zunehd</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zushi</th>\n",
       "      <th>zwolle</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzzzzlullaby</th>\n",
       "      <th>zzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    01  026   04  0430   07   08  0809  0815   09   10  ...  zoya  zune  \\\n",
       "0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   zunehd  zurich  zushi  zwolle  zzz  zzzzz  zzzzzzzzlullaby  zzzzzzzzzzz  \n",
       "0     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "1     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "2     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "3     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "4     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "\n",
       "[5 rows x 11221 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>01</th>\n",
       "      <th>026</th>\n",
       "      <th>04</th>\n",
       "      <th>0430</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>0809</th>\n",
       "      <th>0815</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zune</th>\n",
       "      <th>zunehd</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zushi</th>\n",
       "      <th>zwolle</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzzzzlullaby</th>\n",
       "      <th>zzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    01  026   04  0430   07   08  0809  0815   09   10  ...  zoya  zune  \\\n",
       "0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   zunehd  zurich  zushi  zwolle  zzz  zzzzz  zzzzzzzzlullaby  zzzzzzzzzzz  \n",
       "0     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "1     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "2     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "3     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "4     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "\n",
       "[5 rows x 11221 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_tfidf = test_pipe.transform(covid_raw)\n",
    "covid_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e8233a1-7fc1-4f17-ac11-bf4e63c5631e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.28897039])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_tfidf.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15350a23-4f95-4cd0-864e-7835122756e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>01</th>\n",
       "      <th>026</th>\n",
       "      <th>04</th>\n",
       "      <th>0430</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>0809</th>\n",
       "      <th>0815</th>\n",
       "      <th>09</th>\n",
       "      <th>...</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zune</th>\n",
       "      <th>zunehd</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zushi</th>\n",
       "      <th>zwolle</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzzz</th>\n",
       "      <th>zzzzzzzzlullaby</th>\n",
       "      <th>zzzzzzzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target   01  026   04  0430   07   08  0809  0815   09  ...  zoya  zune  \\\n",
       "0       1  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  ...   0.0   0.0   \n",
       "1       1  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  ...   0.0   0.0   \n",
       "2       0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  ...   0.0   0.0   \n",
       "3       1  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  ...   0.0   0.0   \n",
       "4       1  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "   zunehd  zurich  zushi  zwolle  zzz  zzzzz  zzzzzzzzlullaby  zzzzzzzzzzz  \n",
       "0     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "1     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "2     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "3     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "4     0.0     0.0    0.0     0.0  0.0    0.0              0.0          0.0  \n",
       "\n",
       "[5 rows x 11221 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment140_tfidf = pd.read_parquet(\"s3://twitter-sentiment-analysis-dev/cache/tfidf_data/sentiment140/Sentiment140_tfidf.parquet\")\n",
    "sentiment140_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63d4dbd-e964-41c0-a8ef-75b7f3db0ecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 00:46:47,580:INFO:training: Defining pre-training pipeline.\n",
      "2023-06-11 00:46:47,582:INFO:training: Loading raw sentiment140 dataset.\n",
      "2023-06-11 00:46:48,101:INFO:training: Fitting pre-training pipeline and transforming raw dataset.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:   21.2s remaining:   21.2s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   21.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   21.2s finished\n",
      "2023-06-11 00:47:09,353:INFO:prep: Raw text has been processed for data_key: 'sentiment140'.\n",
      "2023-06-11 00:47:09,525:INFO:prep: Processed data has been saved for data_key: sentiment140.\n",
      "2023-06-11 00:47:09,527:INFO:feature_generation:Found vectorizer. Loading from /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/tfidf_vectorizer.pkl.\n",
      "2023-06-11 00:47:09,531:INFO:feature_generation:Transforming df_proc using fitted Tfidfvectorizer.\n",
      "2023-06-11 00:47:12,256:INFO:feature_generation:Saving tfidf features to s3://twitter-sentiment-analysis-dev/cache/tfidf_data/sentiment140/Sentiment140_tfidf.parquet.\n",
      "2023-06-11 00:47:16,967:INFO:training: Fitting model pipeline.\n",
      "2023-06-11 00:50:03,308:INFO:PCAPlotIt:Target cumulative variance: 0.8\n",
      "2023-06-11 00:50:03,309:INFO:PCAPlotIt:Number of principal components: 2002\n",
      "2023-06-11 00:50:12,072:INFO:training: Saving training pipeline to /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/training_pipeline.pkl.\n",
      "2023-06-11 00:50:17,290:INFO:training: Saving trained pca to /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/trained_pca.pkl.\n",
      "2023-06-11 00:50:22,503:INFO:training: Saving trained model to /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/trained_model.pkl.\n"
     ]
    }
   ],
   "source": [
    "inference_pipeline = train_save_inference_pipeline(save=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69b282c-845d-45c0-8630-9bef95a8bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = inference_pipeline[\"pca\"]\n",
    "x_train_pcs = pca.transform(x_train)\n",
    "x_test_pcs = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19b3785-b2ed-4b57-bd0c-4978009170cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0397941b-6e5d-4df4-9fbd-c2e9025a3ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 21:56:17,708:INFO:evaluation:--------------------COMPUTING CROSS-VALIDATED PERFORMANCE METRICS--------------------\n",
      "\n",
      "2023-06-10 21:56:32,312:INFO:evaluation:Cross-validated precision: 0.7188593023175232\n",
      "2023-06-10 21:56:45,973:INFO:evaluation:Cross-validated recall: 0.7428873706869681\n",
      "2023-06-10 21:56:59,793:INFO:evaluation:Cross-validated f1_macro: 0.7277395508596813\n",
      "2023-06-10 21:57:13,665:INFO:evaluation:Cross-validated roc_auc: 0.8033560000293962\n"
     ]
    }
   ],
   "source": [
    "from birdwatcher.ml.evaluation import get_cv_performance_metrics\n",
    "\n",
    "\n",
    "get_cv_performance_metrics(\n",
    "    clf=inference_pipeline[\"classifier\"],\n",
    "    x_train=x_train_pcs,\n",
    "    y_train=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d88126-fc1a-440c-8502-dd33f36ff533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.90596168, -0.84825256,  2.98537596, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_pipeline[\"classifier\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7463497a-8c0a-40bb-9adf-2a818f6d4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = _get_train_test_data()\n",
    "x_train = train_test.x_train\n",
    "y_train = train_test.y_train\n",
    "x_test = train_test.x_test\n",
    "y_test = train_test.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ee2f799-da25-4718-a06b-5f3db3248638",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline = get_trained_inference_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b24b20be-0671-477a-ac57-76c7bb669590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = inference_pipeline.named_steps[\"pca\"]\n",
    "trained_model = inference_pipeline.named_steps[\"classifier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbae449-1cf5-475e-87f7-3a007db98ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-10 22:12:28,375:INFO:evaluation:--------------------COMPUTING TEST SET PERFORMANCE METRICS--------------------\n",
      "\n",
      "2023-06-10 22:12:28,377:INFO:evaluation:Accuracy: 0.8070929607737776\n",
      "2023-06-10 22:12:28,380:INFO:evaluation:ROC AUC: 0.8779248935614802\n",
      "2023-06-10 22:12:28,382:INFO:evaluation:Confusion matrix:\n",
      "[[763 176]\n",
      " [183 739]]\n",
      "2023-06-10 22:12:28,390:INFO:evaluation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81       939\n",
      "           1       0.81      0.80      0.80       922\n",
      "\n",
      "    accuracy                           0.81      1861\n",
      "   macro avg       0.81      0.81      0.81      1861\n",
      "weighted avg       0.81      0.81      0.81      1861\n",
      "\n",
      "2023-06-10 22:12:28,391:INFO:evaluation:--------------------COMPUTING CROSS-VALIDATED PERFORMANCE METRICS--------------------\n",
      "\n",
      "2023-06-10 22:12:43,339:INFO:evaluation:Cross-validated precision: 0.7142258106705889\n",
      "2023-06-10 22:12:57,588:INFO:evaluation:Cross-validated recall: 0.7357010218677492\n",
      "2023-06-10 22:13:11,832:INFO:evaluation:Cross-validated f1_macro: 0.7230853585615591\n",
      "2023-06-10 22:13:25,690:INFO:evaluation:Cross-validated roc_auc: 0.8005663310666872\n"
     ]
    }
   ],
   "source": [
    "get_model_performance_metrics(\n",
    "    clf=inference_pipeline[\"classifier\"],\n",
    "    x_train=x_train_pcs,\n",
    "    y_train=y_train,\n",
    "    x_test=x_test_pcs,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687931dd-c022-4656-81df-f9188cccc5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_sentiment_raw = pd.read_parquet(\n",
    "    DATA_PREP_CONFIG.processing_info[\"sentiment140\"][\"path_raw\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14ff0062-7ed1-4788-8ffc-e5bbb2bfa020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000333855</td>\n",
       "      <td>Mon Jun 01 21:53:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PlumStSamplers</td>\n",
       "      <td>Sophie's party is so much fun with only 4 girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2054674369</td>\n",
       "      <td>Sat Jun 06 07:51:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>SheaSoul</td>\n",
       "      <td>Here with Phlash. Flight's delayed- shopping t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2031413186</td>\n",
       "      <td>Thu Jun 04 09:46:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>daandewijs</td>\n",
       "      <td>Democracy, its a beast but the best option we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002738455</td>\n",
       "      <td>Tue Jun 02 05:02:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>johnwaire</td>\n",
       "      <td>@bevhollis SCHWEET!  i'm very jealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1835576806</td>\n",
       "      <td>Mon May 18 06:18:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>happyseaurchin</td>\n",
       "      <td>@shixianjia @rosemary0 thankyou for your wishe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                          date      flag            user  \\\n",
       "0  2000333855  Mon Jun 01 21:53:38 PDT 2009  NO_QUERY  PlumStSamplers   \n",
       "1  2054674369  Sat Jun 06 07:51:29 PDT 2009  NO_QUERY        SheaSoul   \n",
       "2  2031413186  Thu Jun 04 09:46:55 PDT 2009  NO_QUERY      daandewijs   \n",
       "3  2002738455  Tue Jun 02 05:02:09 PDT 2009  NO_QUERY       johnwaire   \n",
       "4  1835576806  Mon May 18 06:18:09 PDT 2009  NO_QUERY  happyseaurchin   \n",
       "\n",
       "                                                text  \n",
       "0  Sophie's party is so much fun with only 4 girl...  \n",
       "1  Here with Phlash. Flight's delayed- shopping t...  \n",
       "2  Democracy, its a beast but the best option we ...  \n",
       "3             @bevhollis SCHWEET!  i'm very jealous   \n",
       "4  @shixianjia @rosemary0 thankyou for your wishe...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_raw.iloc[:, 1:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75fb3db0-8baf-40c9-9d16-5b8729fc00ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df_sentiment_raw, \n",
    "    (df_sentiment_raw.iloc[:,0] / 4).astype(int), \n",
    "    test_size=TRAINING_CONFIG.test_size,\n",
    "    random_state=TRAINING_CONFIG.random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97af187-ecf5-4329-bba8-28ece39ff5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   4 | elapsed:    7.0s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.1s finished\n",
      "2023-06-11 00:00:18,440:INFO:prep: Raw text has been processed for data_key: 'sentiment140'.\n",
      "2023-06-11 00:00:18,550:INFO:prep: Processed data has been saved for data_key: sentiment140.\n",
      "2023-06-11 00:00:18,551:INFO:feature_generation:Found vectorizer. Loading from /home/ubuntu/twitter-sentiment-analysis/src/birdwatcher/ml/tfidf_vectorizer.pkl.\n",
      "2023-06-11 00:00:18,557:INFO:feature_generation:Transforming df_proc using fitted Tfidfvectorizer.\n",
      "2023-06-11 00:00:20,389:INFO:feature_generation:Saving tfidf features to s3://twitter-sentiment-analysis-dev/cache/tfidf_data/sentiment140/Sentiment140_tfidf.parquet.\n"
     ]
    }
   ],
   "source": [
    "y_test_preds = inference_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5d6e29c-de6e-4de3-800e-e5c87c414664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3       1\n",
       "4       1\n",
       "6       1\n",
       "7       0\n",
       "10      0\n",
       "       ..\n",
       "1839    1\n",
       "1841    0\n",
       "1843    1\n",
       "1849    1\n",
       "1852    0\n",
       "Name: target, Length: 384, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment140_tfidf.loc[df_sentiment140_tfidf.index.isin(x_test.index), \"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f486f55f-b9bf-430e-ad1f-2639fc697199",
   "metadata": {},
   "outputs": [],
   "source": [
    "from birdwatcher.ml.feature_generation import _get_tfidf_save_path\n",
    "\n",
    "\n",
    "tfidf_path = _get_tfidf_save_path(data_key=\"sentiment140\")\n",
    "df_sentiment140_tfidf = pd.read_parquet(tfidf_path)\n",
    "y_test = df_sentiment140_tfidf.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f473d6b6-47ec-4e72-b767-421ddea545d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8072159396876682"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_score(y_test, y_test_preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twitter_sentiment_analysis]",
   "language": "python",
   "name": "conda-env-twitter_sentiment_analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
